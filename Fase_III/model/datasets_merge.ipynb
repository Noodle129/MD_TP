{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento dados Braga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>q1</th>\n",
       "      <th>q3</th>\n",
       "      <th>stdev</th>\n",
       "      <th>count</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-06T00:00:00.000Z</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>41.5549</td>\n",
       "      <td>-8.4067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-21T00:00:00.000Z</td>\n",
       "      <td>2.90</td>\n",
       "      <td>7.97</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.75</td>\n",
       "      <td>6.63</td>\n",
       "      <td>1.825</td>\n",
       "      <td>4</td>\n",
       "      <td>41.5549</td>\n",
       "      <td>-8.4067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-05T00:00:00.000Z</td>\n",
       "      <td>0.60</td>\n",
       "      <td>9.44</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1.779</td>\n",
       "      <td>91</td>\n",
       "      <td>41.5549</td>\n",
       "      <td>-8.4067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-06T00:00:00.000Z</td>\n",
       "      <td>0.20</td>\n",
       "      <td>22.87</td>\n",
       "      <td>7.73</td>\n",
       "      <td>2.68</td>\n",
       "      <td>10.77</td>\n",
       "      <td>4.815</td>\n",
       "      <td>329</td>\n",
       "      <td>41.5549</td>\n",
       "      <td>-8.4067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-07T00:00:00.000Z</td>\n",
       "      <td>1.27</td>\n",
       "      <td>12.87</td>\n",
       "      <td>5.74</td>\n",
       "      <td>3.77</td>\n",
       "      <td>7.97</td>\n",
       "      <td>2.569</td>\n",
       "      <td>382</td>\n",
       "      <td>41.5549</td>\n",
       "      <td>-8.4067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date   min    max  median    q1     q3  stdev  count  \\\n",
       "0  2020-10-06T00:00:00.000Z  2.92   2.92    2.92  2.92   2.92  0.000      1   \n",
       "1  2020-10-21T00:00:00.000Z  2.90   7.97    4.94  3.75   6.63  1.825      4   \n",
       "2  2020-11-05T00:00:00.000Z  0.60   9.44    2.57  1.88   3.83  1.779     91   \n",
       "3  2020-11-06T00:00:00.000Z  0.20  22.87    7.73  2.68  10.77  4.815    329   \n",
       "4  2020-11-07T00:00:00.000Z  1.27  12.87    5.74  3.77   7.97  2.569    382   \n",
       "\n",
       "   latitude  longitude  \n",
       "0   41.5549    -8.4067  \n",
       "1   41.5549    -8.4067  \n",
       "2   41.5549    -8.4067  \n",
       "3   41.5549    -8.4067  \n",
       "4   41.5549    -8.4067  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset from the file\n",
    "df_pm10 = pd.read_csv('datasets/braga_data_pm10.csv')\n",
    "\n",
    "# Add latitude and longitude columns\n",
    "df_pm10['latitude'] = 41.5549\n",
    "df_pm10['longitude'] = -8.4067\n",
    "\n",
    "# Save the updated dataset back to the file\n",
    "df_pm10.to_csv('datasets/braga_data_pm10_complete.csv', index=False)\n",
    "\n",
    "# Print the first 5 rows of the dataset\n",
    "\n",
    "df_pm10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>q1</th>\n",
       "      <th>q3</th>\n",
       "      <th>stdev</th>\n",
       "      <th>count</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-06T00:00:00.000Z</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>41.5549</td>\n",
       "      <td>-8.4067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-21T00:00:00.000Z</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.241</td>\n",
       "      <td>4</td>\n",
       "      <td>41.5549</td>\n",
       "      <td>-8.4067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-05T00:00:00.000Z</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.621</td>\n",
       "      <td>91</td>\n",
       "      <td>41.5549</td>\n",
       "      <td>-8.4067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-06T00:00:00.000Z</td>\n",
       "      <td>0.10</td>\n",
       "      <td>15.40</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.56</td>\n",
       "      <td>5.45</td>\n",
       "      <td>2.784</td>\n",
       "      <td>329</td>\n",
       "      <td>41.5549</td>\n",
       "      <td>-8.4067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-07T00:00:00.000Z</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.67</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.17</td>\n",
       "      <td>3.13</td>\n",
       "      <td>1.361</td>\n",
       "      <td>382</td>\n",
       "      <td>41.5549</td>\n",
       "      <td>-8.4067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date   min    max  median    q1    q3  stdev  count  \\\n",
       "0  2020-10-06T00:00:00.000Z  1.60   1.60    1.60  1.60  1.60  0.000      1   \n",
       "1  2020-10-21T00:00:00.000Z  0.77   1.45    1.12  0.94  1.29  0.241      4   \n",
       "2  2020-11-05T00:00:00.000Z  0.27   3.40    1.00  0.77  1.55  0.621     91   \n",
       "3  2020-11-06T00:00:00.000Z  0.10  15.40    3.50  0.56  5.45  2.784    329   \n",
       "4  2020-11-07T00:00:00.000Z  0.40   6.67    2.00  1.17  3.13  1.361    382   \n",
       "\n",
       "   latitude  longitude  \n",
       "0   41.5549    -8.4067  \n",
       "1   41.5549    -8.4067  \n",
       "2   41.5549    -8.4067  \n",
       "3   41.5549    -8.4067  \n",
       "4   41.5549    -8.4067  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pm25 = pd.read_csv('datasets/braga_data_pm25.csv')\n",
    "\n",
    "df_pm25['latitude'] = 41.5549\n",
    "df_pm25['longitude'] = -8.4067\n",
    "\n",
    "df_pm25.to_csv('datasets/braga_data_pm25_complete.csv', index=False)\n",
    "\n",
    "df_pm25.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns we need\n",
    "\n",
    "df_updated = df_pm10[['date', 'latitude', 'longitude', 'median']]\n",
    "\n",
    "df_updated.columns = ['date', 'latitude', 'longitude', 'pm10']\n",
    "\n",
    "df_updated.head()\n",
    "\n",
    "df_updated.to_csv('datasets/braga_data_pm10_complete.csv', index=False)\n",
    "\n",
    "df_updated = df_pm25[['date', 'latitude', 'longitude', 'median']]\n",
    "\n",
    "df_updated.columns = ['date', 'latitude', 'longitude', 'pm25']\n",
    "\n",
    "df_updated.head()\n",
    "\n",
    "df_updated.to_csv('datasets/braga_data_pm25_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two datasets into one\n",
    "\n",
    "df_pm10 = pd.read_csv('datasets/braga_data_pm10_complete.csv')\n",
    "df_pm25 = pd.read_csv('datasets/braga_data_pm25_complete.csv')\n",
    "\n",
    "df_merged = pd.merge(df_pm10, df_pm25, on=['date', 'latitude', 'longitude'])\n",
    "\n",
    "df_merged.head()\n",
    "\n",
    "df_merged.to_csv('datasets/braga_41.5549_-8.4067.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento dados Ponte de Lima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pm1 = pd.read_csv('datasets/ponte_lima_data_pm1.csv')\n",
    "df_pm10 = pd.read_csv('datasets/ponte_lima_data_pm10.csv')\n",
    "df_pm25 = pd.read_csv('datasets/ponte_lima_data_pm25.csv')\n",
    "\n",
    "# Add latitude and longitude columns\n",
    "\n",
    "# Select only the columns we need\n",
    "\n",
    "df_pm1 = df_pm1[['date', 'median']]\n",
    "df_pm10 = df_pm10[['date', 'median']]\n",
    "df_pm25 = df_pm25[['date', 'median']]\n",
    "\n",
    "# Rename the columns\n",
    "\n",
    "df_pm1.columns = ['date', 'pm1']\n",
    "df_pm10.columns = ['date', 'pm10']\n",
    "df_pm25.columns = ['date', 'pm25']\n",
    "\n",
    "# Add latitude and longitude columns\n",
    "\n",
    "df_pm1['latitude'] = 41.653315\n",
    "df_pm1['longitude'] = -8.587790\n",
    "\n",
    "df_pm10['latitude'] = 41.653315\n",
    "df_pm10['longitude'] = -8.587790\n",
    "\n",
    "df_pm25['latitude'] = 41.653315\n",
    "df_pm25['longitude'] = -8.587790\n",
    "\n",
    "# Merge the three datasets into one\n",
    "\n",
    "df_merged = pd.merge(df_pm1, df_pm10, on=['date', 'latitude', 'longitude'])\n",
    "df_merged = pd.merge(df_merged, df_pm25, on=['date', 'latitude', 'longitude'])\n",
    "\n",
    "df_merged.head()\n",
    "\n",
    "df_merged.to_csv('datasets/ponte_lima_41.7675_-8.5823.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de dados Vila Verde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('datasets/datavilaverdepm1.csv')\n",
    "df2 = pd.read_csv('datasets/datavilaverdepm25.csv')\n",
    "\n",
    "# Select only the columns we need\n",
    "\n",
    "df1 = df1[['date', 'median']]\n",
    "df2 = df2[['date', 'median']]\n",
    "\n",
    "# Rename the columns\n",
    "\n",
    "df1.columns = ['date', 'pm1']\n",
    "df2.columns = ['date', 'pm25']\n",
    "\n",
    "# Add latitude and longitude columns\n",
    "\n",
    "df1['latitude'] = 41.650791\n",
    "df1['longitude'] = -8.435690\n",
    "\n",
    "\n",
    "df2['latitude'] = 41.650791\n",
    "df2['longitude'] = -8.435690\n",
    "\n",
    "# Merge the two datasets into one\n",
    "\n",
    "df_merged = pd.merge(df1, df2, on=['date', 'latitude', 'longitude'])\n",
    "\n",
    "df_merged.head()\n",
    "\n",
    "df_merged.to_csv('datasets/vila_verde_41.650791_-8.435690.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dataset to have a column called parameter and have pm1, pm10 and pm25 as values and its value in another column\n",
    "\n",
    "df = pd.read_csv('datasets/datasetsfinal/braga_41.5549_-8.4067.csv')\n",
    "\n",
    "df = df.melt(id_vars=['date', 'latitude', 'longitude'], var_name='parameter', value_name='value')\n",
    "\n",
    "df.to_csv('datasets/datasetsfinal/teste1.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('datasets/datasetsfinal/ponte_lima_41.7675_-8.5823.csv')\n",
    "\n",
    "df = df.melt(id_vars=['date', 'latitude', 'longitude'], var_name='parameter', value_name='value')\n",
    "\n",
    "df.to_csv('datasets/datasetsfinal/teste2.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('datasets/datasetsfinal/vila_verde_41.650791_-8.435690.csv')\n",
    "\n",
    "df = df.melt(id_vars=['date', 'latitude', 'longitude'], var_name='parameter', value_name='value')\n",
    "\n",
    "df.to_csv('datasets/datasetsfinal/teste3.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('datasets/datasetsfinal/teste1.csv')\n",
    "\n",
    "df = df.append(pd.read_csv('datasets/datasetsfinal/teste2.csv'))\n",
    "\n",
    "df = df.append(pd.read_csv('datasets/datasetsfinal/teste3.csv'))\n",
    "\n",
    "df.to_csv('datasets/datasetsfinal/braga_ponte_lima_vila_verde.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('datasets/datasetsfinal/braga_ponte_lima_vila_verde.csv')\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Put the df into a csv\n",
    "\n",
    "df.to_csv('datasets/datasetsfinal/braga_ponte_lima_vila_verde.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento Dataset Braga v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['utc'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-c5a02d635bdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Select only the columns we need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf_braga\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_braga\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'parameter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'longitude'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Rename the columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2910\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;31m# we skip the warning on Categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['utc'] not in index\""
     ]
    }
   ],
   "source": [
    "# Read the dataset from the file\n",
    "\n",
    "df_braga = pd.read_csv('datasets/datasetsfinal/braga_41.449722_-8.296389.csv')\n",
    "\n",
    "# Select only the columns we need\n",
    "\n",
    "df_braga = df_braga[['utc', 'parameter', 'value', 'longitude', 'latitude']]\n",
    "\n",
    "# Rename the columns\n",
    "\n",
    "df_braga.columns = ['date', 'parameter', 'value', 'longitude', 'latitude']\n",
    "\n",
    "# Change the date format\n",
    "\n",
    "df_braga['date'] = pd.to_datetime(df_braga['date'])\n",
    "\n",
    "df_braga.head()\n",
    "\n",
    "# Put the df into a csv\n",
    "\n",
    "df_braga.to_csv('datasets/datasetsfinal/braga_41.449722_-8.296389.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the datasets\n",
    "\n",
    "df_braga = pd.read_csv('datasets/datasetsfinal/braga_41.449722_-8.296389.csv')\n",
    "\n",
    "df_total = pd.read_csv('datasets/datasetsfinal/braga_ponte_lima_vila_verde.csv')\n",
    "\n",
    "df_final = df_total.append(df_braga)\n",
    "\n",
    "df_final.head()\n",
    "\n",
    "df_final.to_csv('datasets/datasetsfinal/FINAL.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "df_meteo = pd.read_csv('datasets/datasetsfinal/Bragatempo.csv')\n",
    "\n",
    "# Select only the columns we need\n",
    "\n",
    "df_meteo = df_meteo[['datetime', 'tempmax', 'tempmin', 'temp', 'feelslike', 'dew', 'humidity', 'severerisk', 'precip', 'snow', 'windspeed', 'sealevelpressure' ,'cloudcover' , 'visibility' , 'solarradiation' , 'solarenergy' ,'uvindex' ]]\n",
    "\n",
    "# Rename the column datetime to date\n",
    "\n",
    "df_meteo.columns = ['date', 'tempmax', 'tempmin', 'temp', 'feelslike', 'dew', 'humidity', 'severerisk', 'precip', 'snow', 'windspeed', 'sealevelpressure' ,'cloudcover' , 'visibility' , 'solarradiation' , 'solarenergy' ,'uvindex' ]\n",
    "\n",
    "# Add the latitude and longitude columns and fill them with the values randomized from the pair of coordinates [41.5549,-8.4067], [41.653315,-8.58779], [41.449721999999994,-8.296389], [41.650791,-8.43569]\n",
    "\n",
    "coordinates = [[41.5549, -8.4067], [41.653315, -8.58779], [41.449721999999994, -8.296389], [41.650791, -8.43569]]\n",
    "\n",
    "df_meteo['latitude'] = [random.choice(coordinates)[0] for _ in range(len(df_meteo))]\n",
    "df_meteo['longitude'] = [random.choice(coordinates)[1] for _ in range(len(df_meteo))]\n",
    "\n",
    "df_meteo.head()\n",
    "\n",
    "df_meteo.to_csv('datasets/datasetsfinal/meteo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataset braga_ponte_lima_vila_verde.csv with the dataset meteo.csv\n",
    "\n",
    "df_meteo = pd.read_csv('datasets/datasetsfinal/meteo.csv')\n",
    "\n",
    "df_total = pd.read_csv('datasets/FINALDATASET.csv')\n",
    "\n",
    "dates1 = set(df_meteo['date'])\n",
    "dates2 = set(df_total['date'])\n",
    "\n",
    "# Find the common dates\n",
    "common_dates = dates1.intersection(dates2)\n",
    "\n",
    "# Filter the datasets by the common dates\n",
    "\n",
    "df_meteo = df_meteo[df_meteo['date'].isin(common_dates)]\n",
    "df_total = df_total[df_total['date'].isin(common_dates)]\n",
    "\n",
    "# Merge the datasets\n",
    "\n",
    "df_final = pd.merge(df_total, df_meteo, on=['date', 'latitude', 'longitude'])\n",
    "\n",
    "df_final.head()\n",
    "\n",
    "df_final.shape\n",
    "\n",
    "df_final.to_csv('datasets/datasetsfinal/FINALDATASETmerged.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
